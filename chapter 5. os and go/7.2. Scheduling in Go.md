# Scheduling in Go

https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part1.html
https://golangbyexample.com/goroutines-golang/

## Part 1 - OS Scheduler

### Introduction

The design and behavior of the Go scheduler allows your multithreaded Go programs to be more efficient and performant. It's important to have a general and representative understanding of how both the OS and Go schedulers work to design our multithreaded software correctly.

### OS scheduler

Operating system schedulers are complex pieces of software. You program is just a series of machine instructions that need to be executed one after the other sequentially. To make that happen, the os uses the concept of Thread. It's the job of the Thread to account for and sequentially execute the set of instruction it's assigned. Execution continues until there are no more instructions for the Thread to execute.

The OS scheduler is responsible for making sure cores are not idle if there are Threads that can be executing. It must also create the illusion that all the Threads that can executing at the same time. In the process of creating this illusion, the scheduler needs to run Threads with a higher priority over lower priority Threads. However, Threads with a lower priority can't be starved of execution time. The scheduler also needs to minimize scheduling latencies as much as possible by making quick and smart decisions.

### Executing Instructions

The program counter (PC) which is sometimes called the instruction pointer (IP), is what allows the Thread to keep track of the next instruction to execute. In most processors, the PC points to the next instruction and not the current instruction.

The computer keeps track of the next line be executed by keeping its address in a special register called the Instruction Pointer (IP) or Program Counter.

The contents of this register is updated with every instrucion executed

Thus a program is executed sequentially line by line

### Thread States

A Thread can be in one of three states: Waiting, Runnable or Executing

### Types of Work

There are two types of work a Thread can do. The first is called CPU-Bound and the second is called IO-Bound.

**CPU-Bound:** This is work that never creates a situation where the Thread may be placed in Waiting states. This is work that is constantly making caculations.

**IO-Bound:** This is work that causes Threads to enter into Waiting states. This is work that consists in requesting access to a resource over the network or making system calls into the operation system. A Thread that needs to access a database would be IO-bound. I would include synchronization events (mutexes, atomic), that cause the Thread to wait as part of this category.

### Context Switching

If you are running on Linux, Mac or Windows, you are running on an OS that has a preemptive scheduler. This means a few important things.

First, it means the scheduler is unpredictable when it comes to what Threads will be chosen to run at any given time. Thread priorities together with events make it impossible to determine what the scheduler will choose to do and when. 

Second, it means you must never write code based on some perceived behavior that you have been luchky to experience but is not guaranteed to take place every time. It is easy to allow yourself to think, because i've seen this happen the same way 1000 times, this is guaranteed behavior. You must control the synchronization and orchestration of Threads if you need determinism in your application.

The physical act of swapping Threads on a core is called a context switching. A context switching happens when the scheduler pulls an Executing thread off a core and replaces it with a Runnable Thread. The Thread that was selected from the run queue moves into an Executing state. The Thread that was pulled can move back into a Runnable state (if it still has the ability to run), or into a Waiting state(if was replaced because of an IO-bound type of request).

Context switches are considered to be expensive because it takes times to swap Threads on and off a core. The amount of latency incurrent during a context switch depends on different factors but it's not unreasonable for it to take between 1000 and 1500 nanoseconds. Considering the hardware should be able to reasonably execute (on average) 12 instructions per nanosecond per core, a context switch can const you 12K to 18K instructions of latency. In essence, you program is losing the ability to execute a large number of instructions during a context switching.

If you have a program that is focused on IO-Bound work, then the context switches are going to be an advantages. Once a Thread moves into a Waiting state, another Thread in a Runnable state is there to take its place. This allows the core to always be doing work. This is one of the most important aspects of scheduling. **Don't allow a core to go idle if there is work(Threads in a Runnable state) to be done**

If you program is focused on CPU-Bound work, then context switches are going to be a performance nightmare. Since the Thread always has work to do, the context-switch is stopping that work from progressing. This situation is in stark contrast with what happens with an IO-Bound workload.

### Less is More

### Find the balance

### Cache lines

### Scheduling decision scenario

### Conclusion

The first part of the post provides insights into what you have to consider regarding Threads and the OS scheduler when writing multithreaded applications. These are the things the Go scheduler takes into consideration as well.